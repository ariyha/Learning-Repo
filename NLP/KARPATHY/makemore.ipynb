{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(word) for word in words),max(len(word) for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>']+list(w)+['<E>']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        b[bigram] = b.get(bigram,0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S>', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '<E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S>', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '<E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S>', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '<E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S>', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S>', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S>', 'l'), 1572),\n",
       " (('<S>', 'c'), 1542),\n",
       " (('<S>', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '<E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '<E>'), 1314),\n",
       " (('<S>', 't'), 1308),\n",
       " (('<S>', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '<E>'), 1169),\n",
       " (('<S>', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S>', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S>', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '<E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S>', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S>', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S>', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '<E>'), 516),\n",
       " (('d', '<E>'), 516),\n",
       " (('<S>', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '<E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S>', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S>', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S>', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '<E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S>', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '<E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '<E>'), 160),\n",
       " (('u', '<E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S>', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '<E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '<E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '<E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S>', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '<E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '<E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S>', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '<E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '<E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '<E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '<E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(),key=lambda v:v[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27))\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.']+list(w)+['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        N[stoi[ch1],stoi[ch2]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d29b8b4a10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0., 4410., 1306., 1542., 1690., 1531.,  417.,  669.,  874.,  591.,\n",
       "        2422., 2963., 1572., 2538., 1146.,  394.,  515.,   92., 1639., 2055.,\n",
       "        1308.,   78.,  376.,  307.,  134.,  535.,  929.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p/p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.multinomial(p,num_samples=1,replacement=True,generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P = P/P.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drla.\n",
      "kedrphannon.\n",
      "ja.\n",
      "rys.\n",
      "ah.\n",
      "kee.\n",
      "a.\n",
      "miolaronab.\n",
      "bremind.\n",
      "seelyan.\n",
      "a.\n",
      "kly.\n",
      "alivessgryaja.\n",
      "laveildug.\n",
      "s.\n",
      "wea.\n",
      "an.\n",
      "keron.\n",
      "kus.\n",
      "nlely.\n",
      "keieee.\n",
      "gajamonian.\n",
      "gann.\n",
      "azdirmay.\n",
      "ka.\n",
      "amae.\n",
      "le.\n",
      "miadydon.\n",
      "khin.\n",
      "dellya.\n",
      "kaialla.\n",
      "shashocawhalliaramme.\n",
      "amax.\n",
      "ayalelisamacamiatreie.\n",
      "duadhy.\n",
      "eimpra.\n",
      "alee.\n",
      "s.\n",
      "dokhiard.\n",
      "jyighuda.\n",
      "lyawimo.\n",
      "s.\n",
      "tonopha.\n",
      "mada.\n",
      "li.\n",
      "an.\n",
      "juerarexlana.\n",
      "tykee.\n",
      "lyimb.\n",
      "han.\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p,num_samples=1,replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix==0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".a : 0.1376 : -1.9835\n",
      "an : 0.1604 : -1.8302\n",
      "nd : 0.0384 : -3.2594\n",
      "dr : 0.0770 : -2.5646\n",
      "re : 0.1334 : -2.0143\n",
      "ej : 0.0027 : -5.9004\n",
      "jq : 0.0003 : -7.9817\n",
      "q. : 0.0970 : -2.3331\n",
      "Log Likelihood -27.8672\n",
      "Negative Log Likelihood 3.4834\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0\n",
    "n=0\n",
    "for w in [\"andrejq\"]:\n",
    "    chs = ['.']+list(w)+['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood+=logprob\n",
    "        print(f'{ch1}{ch2} : {prob:.4f} : {logprob:.4f}')\n",
    "        n+=1 \n",
    "\n",
    "print('Log Likelihood {:.4f}'.format(log_likelihood))\n",
    "nll = -log_likelihood/n\n",
    "print('Negative Log Likelihood {:.4f}'.format(nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys=[],[]\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.']+list(w)+['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs,27).float()\n",
    "W = torch.randn((27,27),requires_grad=True)\n",
    "logits = xenc@W\n",
    "counts = logits.exp()\n",
    "prob = counts/counts.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(5),ys].log().mean()\n",
    "loss = loss.reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.grad=None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt','r').read().splitlines()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(words):\n",
    "    block_size =3\n",
    "    X,Y = [],[]\n",
    "    for w in words:\n",
    "        context = [0]*block_size\n",
    "\n",
    "        for ch in w +'.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:]+[ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X,Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,Ytr = build_data(words[:n1])\n",
    "Xdev,Ydev = build_data(words[n1:n2])\n",
    "Xte,Yte = build_data(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,10))\n",
    "W1 = torch.randn((30,200)) * (5/3)/(30**0.5)\n",
    "b1 = torch.randn(200) *0.01\n",
    "W2 = torch.randn((200,27))*0.01\n",
    "b2 = torch.randn(27)*0 \n",
    "\n",
    "bngain = torch.ones(200)\n",
    "bnbias = torch.zeros(200)\n",
    "\n",
    "parameters = [C,W1,b1,W2,b2,bngain,bnbias]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3,0,1000)\n",
    "lrs = 10**(lre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 3.2804195880889893\n",
      "1000 : 2.714069366455078\n",
      "2000 : 2.214885711669922\n",
      "3000 : 2.329810619354248\n",
      "4000 : 2.568671941757202\n",
      "5000 : 2.039724349975586\n",
      "6000 : 2.2951436042785645\n",
      "7000 : 2.1791603565216064\n",
      "8000 : 2.058154582977295\n",
      "9000 : 2.0148956775665283\n",
      "10000 : 2.211763858795166\n",
      "11000 : 2.4062557220458984\n",
      "12000 : 1.9392246007919312\n",
      "13000 : 2.118886947631836\n",
      "14000 : 2.042309045791626\n",
      "15000 : 2.4728360176086426\n",
      "16000 : 2.4327640533447266\n",
      "17000 : 2.0383951663970947\n",
      "18000 : 2.3733224868774414\n",
      "19000 : 1.978621006011963\n",
      "20000 : 2.205040454864502\n",
      "21000 : 2.188453435897827\n",
      "22000 : 2.1326510906219482\n",
      "23000 : 2.155259370803833\n",
      "24000 : 2.182513475418091\n",
      "25000 : 1.8971291780471802\n",
      "26000 : 2.474544048309326\n",
      "27000 : 2.3621768951416016\n",
      "28000 : 2.2343926429748535\n",
      "29000 : 1.80777907371521\n"
     ]
    }
   ],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(30000):\n",
    "    ix = torch.randint(0,Xtr.shape[0],(32,))\n",
    "    emb = C[Xtr[ix]]\n",
    "    hpreact = emb.reshape(emb.shape[0],-1)@W1+b1\n",
    "    hpreact = bngain*(hpreact-hpreact.mean(0,keepdim=True))/hpreact.std(0,keepdim=True) + bnbias\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h@W2+b2\n",
    "    loss = F.cross_entropy(logits,Ytr[ix])\n",
    "    if i%1000==0:\n",
    "        print(i,\":\",loss.item())\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad=None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data+=-lr*p.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xtr]\n",
    "    hpreact = emb.reshape(emb.shape[0],-1)@W1+b1\n",
    "    hpreact = bngain*(hpreact-hpreact.mean(0,keepdim=True))/hpreact.std(0,keepdim=True) + bnbias\n",
    "    bnmean = hpreact.mean(0,keepdim=True)\n",
    "    bnstd = hpreact.std(0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0831332206726074\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.209313154220581\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "hpreact = emb.reshape(emb.shape[0],-1)@W1+b1\n",
    "hpreact = bngain*(hpreact-hpreact.mean(0,keepdim=True))/hpreact.std(0,keepdim=True) + bnbias\n",
    "h = torch.tanh(hpreact)\n",
    "logits = h@W2+b2\n",
    "loss = F.cross_entropy(logits,Ydev)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2114341259002686\n"
     ]
    }
   ],
   "source": [
    "emb = C[Xte]\n",
    "hpreact = emb.reshape(emb.shape[0],-1)@W1+b1\n",
    "hpreact = bngain*(hpreact-hpreact.mean(0,keepdim=True))/hpreact.std(0,keepdim=True) + bnbias\n",
    "h = torch.tanh(hpreact)\n",
    "logits = h@W2+b2\n",
    "loss = F.cross_entropy(logits,Yte)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch'fy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) #* 0.2\n",
    "#b1 = torch.randn(n_hidden,                        generator=g) * 0.01\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.01\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47024\n"
     ]
    }
   ],
   "source": [
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      xmean = x.mean(0, keepdim=True) # batch mean\n",
    "      xvar = x.var(0, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "layers = [\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size),\n",
    "]\n",
    "# layers = [\n",
    "#   Linear(n_embd * block_size, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, vocab_size),\n",
    "# ]\n",
    "\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  layers[-1].gamma *= 0.1\n",
    "  #layers[-1].weight *= 0.1\n",
    "  # all other layers: apply gain\n",
    "  for layer in layers[:-1]:\n",
    "    if isinstance(layer, Linear):\n",
    "      layer.weight *= 1.0 #5/3\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2870\n"
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for layer in layers:\n",
    "    layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "college",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
